<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://chusi-truth.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://chusi-truth.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-09-14T06:49:57+00:00</updated><id>https://chusi-truth.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">understanding DDPM</title><link href="https://chusi-truth.github.io/blog/2025/understanding-ddpm/" rel="alternate" type="text/html" title="understanding DDPM"/><published>2025-09-13T21:24:00+00:00</published><updated>2025-09-13T21:24:00+00:00</updated><id>https://chusi-truth.github.io/blog/2025/understanding-ddpm</id><content type="html" xml:base="https://chusi-truth.github.io/blog/2025/understanding-ddpm/"><![CDATA[<h1 id="ddpm扩散模型梦开始的地方">DDPM：扩散模型梦开始的地方</h1> <h2 id="为什么是-ddpm">为什么是 DDPM</h2> <p>答案很简单：因为最近扩散模型很火，因此为了蹭上一波热度开始了解扩散模型的方向。DDPM作为一个比较经典的扩散模型，具有较为复杂的数学推导。在学习过程中容易出现理论与代码实践切割的情况。因此这篇文章希望能够统一地介绍DDPM的数学原理以及具体的代码实现。</p> <h2 id="直观感受">直观感受</h2> <h3 id="源自非平衡态热力学的启发">源自非平衡态热力学的启发</h3> <p>DDPM的核心思想是模仿物理世界中粒子扩散的过程。例如，一滴墨水在水中逐渐散开，最终均匀分布，这是一个从有序到无序的过程。DDPM通过学习这个过程的逆过程，从完全无序的噪声中逐步恢复出有序、清晰的图案。</p> <h4 id="前向扩散过程">前向扩散过程</h4> <p>这个过程是非平衡热力学中的熵增过程，系统从有序变得无序。在DDPM中，这个过程表现为一张图像和一个高斯噪声按照一定比例混合，形成新的图像，经过多次上述操作后，我们可以得到一张约为完全噪音的图像。</p> <h4 id="反向去噪过程">反向去噪过程</h4> <p>这个过程是前向扩散过程的逆过程，系统从无序变得有序。在DDPM中，这个过程表现为，给模型一张带有噪音的图像，模型尝试生成其中噪音的部分并将其去除。给模型一张纯噪音图像，经过多次去噪，我们就有可能得到一张清晰的图像。</p> <h2 id="数学原理">数学原理</h2> <p>针对上述直观的过程，我们下面进行较为严格的数学推导。</p> <h3 id="加噪与去噪">加噪与去噪</h3> <p>我们首先定义时间步 \(T\) ，这表示我们总共需要加噪，去噪 \(T\) 次之后才能得到一张完全的噪声图像或生成图像。特别地，我们使用 \(x_t\) 表示目前的图像被加噪了多少次。\(x_0\) 表示这是一张没有经过加噪的正常图像，\(x_T\) 表示这是一张经过 \(T\) 次加噪后得到的一张噪声图像。</p> <p>加噪过程的每一步，都只与当前图像有关，而与再之前的图像无关。这说明，加噪过程是一个马尔科夫链。去噪过程我们也假设可以写成一个马尔科夫链。</p> <p>对于加噪过程，DDPM定义为：</p> \[q(x_t|x_{t-1}):=\mathcal{N}(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_t \mathbf{I})\] <p>对于去噪过程，DDPM 定义为：</p> \[p_\theta(x_{t-1}|x_t):=\mathcal{N}（x_{t-1};\mu_\theta(x_t,t),\Sigma_\theta(x_t,t)) \\\] <p>另外，还有加噪轨迹和去噪轨迹：</p> \[q(x_{1:T}|x_0):=\prod_{t=1}^Tq(x_t|x_{t-1}) \\p_\theta(x_{0:T}):=p(x_T)\prod_{t=1}^Tp_\theta(x_{t-1}|x_t)\] <blockquote> <p>[!note]</p> <p>其中，\(\{\beta_t\}\) 是一族超参数，不需要模型学习。去噪过程中高斯分布的均值和方差与图像和时间步相关，在具体实现的时候。DDPM 将 \(\Sigma_\theta\) 设为了一组只和时间步相关的常数 \(\sigma_t^2\)</p> </blockquote> <h3 id="损失函数">损失函数</h3> <p>由于我们从噪声生成图像的过程中，希望能够生成给定的图像 \(x_0\) ，因此我们要计算 \(p_\theta(x_0)\) :</p> \[p_\theta(x_0)=\int p_\theta(x_{0:T})dx_{1:T} \\ p_\theta(x_{0:T}):=p(x_T)\prod_{t=1}^{T}p_\theta(x_{t-1}|x_t) \\ p_\theta(x_{t-1}|x_t):=\mathcal{N}(x_{t-1};\mu_\theta(x_t,t),\Sigma_\theta(x_t,t))\] <p>模型学习的分布应当尽量与数据集中的分布一致，而我们可以把数据集中每一个图像看作一类。这样，我们可以把 DDPM 看作一个分类模型（虽然数据是连续的）：给定一个高斯噪声，通过不断去噪得到它正确的分类（图像结果），因此我们可以用交叉熵作为损失函数。</p> \[\mathbb{E}[-\log p_\theta(x_0)]\] <p>然而，在实际过程中我们很难计算 \(p_\theta(x_0)\) ， 因此通过变分推断近似解决： $$</p> <table> <tbody> <tr> <td>\mathbb{E}[-\log p_\theta(x_0)] \le \mathbb{E}<em>{x_0,q}[-\log\frac{p</em>\theta(x_{0:T})}{q(x_{1:T}</td> <td>x_0)}]</td> </tr> </tbody> </table> <p>\=\mathbb{E}<em>{x_0,q}[-\log p(x_T)-\sum</em>{t \ge 1}\log\frac{p_\theta(x_{t-1}|x_t)}{q(x_t|x_{t-1})}]=:L $$</p> <blockquote> <p>[!note]</p> <table> <tbody> <tr> <td>观察不等式的两边，我们注意到，通过变分推断，我们避免了计算难以解析的高维积分，而是通过改为计算 $$\log\frac{p_\theta(x_{0:T})}{q(x_{1:T}</td> <td>x_0)}\(对分布\)q(x_{1:T</td> <td>x_0})\(的期望来计算\)\log p_\theta(x_0)$$ 的下界。</td> </tr> </tbody> </table> <p>因此，需要注意损失函数实际上要最小化的是两层期望。</p> <p><a href="#证明附录">详细证明见附录</a></p> </blockquote> <p>通过变换，\(L\) 可以被重写为如下形式：</p> \[\mathbb{E}_{x_0,q}[D_{KL}(q(x_T|x_0)||p(x_T))+\sum_{t&gt;1}D_{KL}(q(x_{t-1}|x_t,x_0)||p_\theta(x_{t-1}|x_t)) \\-\log p_\theta(x_0|x_1)]\] <p>期望中从左到右的三项分别称之为 \(L_T, L_{t-1}, L_0\)。这样写的好处在于，我们可以对模型训练的目标有一个清晰而直观的理解：</p> <p>\(L_T\) 试图让加噪生成的噪声图像的分布尽量接近于生成图像时采样噪声的分布。在 DDPM 中，由于 \(q\) 和 \(p(x_T)\) 实际上都是已知的，因此 \(L_T\) 是一个可以忽略的常数项。</p> <p>\(L_{t-1}\) 试图让可学习的分布 \(p_\theta\) 去尽量逼近加噪过程的逆过程。这实际上就是在学习预测噪声。</p> <p>\(L_0\) 实际上就是负对数化似然。</p> <blockquote> <p>[!note]</p> <p>KL 散度是信息论中的一个概念，用来衡量两个分布之间的差异。 \(D_{KL}(P||Q)=\int P(X)\log \frac{P(X)}{Q(X)}dx\) 性质：</p> <ul> <li>非负性：取零时，当且仅当 \(P=Q\)</li> <li> <table> <tbody> <tr> <td>不对称性：$$D_{KL}(P</td> <td> </td> <td>Q) \ne D_{KL}(Q</td> <td> </td> <td>P)$$</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>期望形式：$$D_{KL}(P</td> <td> </td> <td>Q)=\mathbb{E}[\log P(x)-\log Q(x)]$$</td> </tr> </tbody> </table> </li> </ul> </blockquote> <blockquote> <p>[!important]</p> <p>一个令人疑惑的点是：\(L_0\) 实际上也是预测噪声的一部分，为什么不能并入 \(L_{t-1}\) 呢？</p> <p>问题在于，\(t=1\) 时的 KL 散度形式为： \(KL(q(x_0|x_1,x_0)||p_\theta(x_0|x_1))\) 但是 \(q(x_0|x_1,x_0)\) 是一个退化分布，退化分布与一半分布的 KL 散度不能写成常规形式，否则会遇到奇异性问题。</p> </blockquote> <h3 id="加噪技巧">加噪技巧</h3> <p>由于 DDPM 的性质，加噪是一步一步地进行的。这是否意味着我们如果想得到一张时间步 \(t\) 的加噪图像，我们真的需要老老实实地加噪 \(t\) 次呢？NO！实际上我们有：</p> \[q(x_t|x_0)=\mathcal{N}(x_t;\sqrt{\bar{\alpha_t}}x_0,(1-\bar{\alpha_t})\mathbf{I}) \\ \alpha:=1-\beta_t \\ \bar{\alpha_t}:=\prod_{s=1}^t\alpha_s\] <blockquote> <p>[!note]</p> <p>根据加噪的定义 \(q(x_t|x_{t-1})=\mathcal{N}(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_t \mathbf{I})\) ，我们可以将它重新写为递推形式： \(x_t=\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}\epsilon_t \\ \epsilon \sim \mathcal{N}(0,\mathbf{I})\) 我们递归地展开一项这个递推式，可以得到： \(x_{t+1}=\sqrt{\alpha_{t+1}}(\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}\epsilon_t)+\sqrt{1-\alpha_{t+1}}\epsilon_{t+1} \\ =\sqrt{\alpha_{t+1}\alpha_t}x_{t-1}+\sqrt{\alpha_{t+1}(1-\alpha_t)}\epsilon_t+\sqrt{1-\alpha_{t+1}}\epsilon_{t+1}\) 如果一直展开到 \(x_0\) ，我们有： \(x_t=\sqrt{\prod_{s=1}^t\alpha_s}x_0+\sum_{s=1}^t\sqrt{(1-\alpha_s)\prod_{j=s+1}^t\alpha_j}\epsilon_s\) 方差项通过数学归纳法可以发现等同于 \(1-\bar{\alpha}_t\)，均值项显然。</p> </blockquote> <h3 id="去噪技巧">去噪技巧</h3> <p>由于加噪的分布和尝试学习的分布都是高斯分布，根据多元高斯 KL 公式，\(L_{t-1}\) 可以被重写为<a href="#证明附录">如下形式：</a></p> \[L_{t-1}=\mathbb{E}_q[\frac{1}{2\sigma_t^2}||\tilde{\mu}_t(x_t,x_0)-\mu_\theta(x_t,t)||^2]+C\] <blockquote> <p>[!note]</p> <p>可以算出： \(q(x_{t-1}|x_t,x_0)=\mathcal{N}(x_{t-1};\tilde{\mu}_t(x_t,x_0),\tilde{\beta}_t\mathbf{I}) \\ \tilde \mu_t(x_t,x_0):=\frac{\sqrt{\bar \alpha_{t-1}}\beta_t}{1-\bar \alpha_t}x_0+\frac{\sqrt {\alpha_t}(1-\bar \alpha_{t-1})}{1-\bar \alpha_t}x_t \\ \tilde \beta_t:=\frac{1-\bar{\alpha}_{t-1}}{1-\bar \alpha_t}\beta_t\)</p> </blockquote> <blockquote> <p>[!important]</p> <p>这里可能存在一个疑惑：对 \(q\) 求期望，但是期望项里并没有出现 \(q\) 啊？在这里我们可以把 \(q\) 理解为一次采样过程。其中 \(x_t\) 和 \(t\) 就是在时间步 \(t\) 时的结果。</p> </blockquote> <p>对于重写的损失形式，一个直觉是我们直接学习 \(\tilde \mu_t\) 。然而通过进一步展开上述损失，我们可以得到：</p> \[L_{t-1}-C=\mathbb E_{x_0,\epsilon}[\frac{1}{2\sigma^2_t}||\frac{1}{\sqrt \alpha_t}(x_t(x_0,\epsilon)-\frac{\beta_t}{\sqrt{1-\bar \alpha_t}}\epsilon)-\mu_\theta(x_t(x_0,\epsilon),t)||^2]\] <p>因此在去噪的时候，DDPM 实际上是先学习去噪分布的均值 \(\mu_\theta(x_t,t)=\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar \alpha_t}}\epsilon)\)，再在这个均值上添加一个随机噪声 \(x_{t-1}=\mu_\theta(x_t,t)+\sigma_t\mathbf z\)，得到去噪图像的。</p> <p>一种现在更常见的操作是预测噪声：注意到上面对均值的预测中，由于 \(x_t\) 可以直接作为输入，实际上只有噪声是需要预测的未知量。因此一个motivating 的选择是：</p> \[\mu_\theta(x_t,t)=\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar \alpha_t}}\epsilon_\theta(x_t,t))\] <p>将其重新带回重写后的损失函数后可以得到：</p> \[L_{t-1}-C=\mathbb{E}_{x_0,\epsilon}[\frac{\beta_t^2}{2\sigma^2_t(1-\bar \alpha_t)}||\epsilon-\epsilon_\theta(\sqrt{\bar \alpha_t}x_0+\sqrt{1-\bar \alpha_t }\epsilon,t)||^2]\] <p>这样做的好处是，网络只需要学习一个更为简洁的函数。</p> <blockquote> <p>[!note]</p> <p>\(\epsilon_\theta\) 是噪声预测器，用来预测噪声，\(\mu_\theta\) 用来预测去噪结果的均值。在这次重写中我们把一次采样过程分解为了两步：采样原始图像与采样噪声。</p> <p>这里有值得注意的一点：\(\mathbf{z}\) 代表的并不是所谓的噪音，而是一种随机采样。这很像 VAE 中的重参数化技巧：去噪结果实际上也是一个随机变量，是神经网络无法学习的。但是我们可以通过学习这个分布的均值，并随机给这个均值加上一个高斯分布的采样结果，来实现随机化。</p> </blockquote> <h2 id="工程实现">工程实现</h2> <h3 id="数据预处理">数据预处理</h3> <h4 id="数据放缩">数据放缩</h4> <p>DDPM 在原始论文中指出，他们驶使用的图片数据集由 0-255 的整数构成。他们将数据范围从 0-255 线性地缩小到了 [-1,1]</p> <h4 id="解码器">解码器</h4> <p>在反向过程中，由于去噪过程中会出现对高斯分布采样结果的加减，这导致我们最后得到数据不一定能通过数据放缩的逆过程重新转化为 0-255 的整数。因此 ddpm 选择在 \(x_1\) 进行去噪的过程中，直接计算每一个像素点是 0-255 的概率。解码公式如下：</p> \[p_\theta(x_0|x_1)=\prod_{i=1}^D\int_{\delta_\_(x_0^i)}^{\delta_+(x_0^i)}\mathcal{N}(x;\mu_\theta^i(x_1,1),\sigma^2_1)dx \\ \delta^+(x) = \begin{cases} +\infty, &amp; x = 1 \\ x + \tfrac{1}{255}, &amp; x &lt; 1 \end{cases} \quad \quad \delta^-(x) = \begin{cases} -\infty, &amp; x = -1 \\ x - \tfrac{1}{255}, &amp; x &gt; -1 \end{cases}\] <p>公式看上去吓人，但是实际上是一个很直观的结果：在预测完 \(x_0\) 的均值后，我们得到一个关于这个均值的高斯分布。通过将这个分布在 x 轴等分 256 份，并计算每部分的面积，我们实际上就得到了高斯分布采样落在这每一部分的概率。第 k 份的区间是 \([k-\frac{1}{255},k+\frac{1}{255}]\)，代表着落在整数 k 附近的概率。这样我们就得到了每个像素点取值的概率分布，我们可以根据不同的选取策略进行实际的赋值。</p> <h3 id="训练过程">训练过程</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">each</span> <span class="n">training</span> <span class="n">step</span><span class="p">:</span>
    <span class="n">x0</span> <span class="o">~</span> <span class="n">dataset</span>                          <span class="c1"># 从数据集中采样图像
</span>    <span class="n">t</span> <span class="o">~</span> <span class="nc">Uniform</span><span class="p">({</span><span class="mi">1</span><span class="p">,...,</span><span class="n">T</span><span class="p">})</span>                <span class="c1"># 随机选择一个时间步 t
</span>    <span class="n">ε</span> <span class="o">~</span> <span class="nc">N</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">I</span><span class="p">)</span>                            <span class="c1"># 采样标准高斯噪声
</span>    <span class="n">xt</span> <span class="o">=</span> <span class="nf">sqrt</span><span class="p">(</span><span class="n">alpha_bar_t</span><span class="p">)</span><span class="o">*</span><span class="n">x0</span> <span class="o">+</span> <span class="nf">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha_bar_t</span><span class="p">)</span><span class="o">*</span><span class="n">ε</span>  <span class="c1"># 添加噪声，alpha_bar_t = ∏_{s=1}^t (1-βs)
</span>    
    <span class="c1"># 预测噪声并计算损失
</span>    <span class="n">ε_theta</span> <span class="o">=</span> <span class="nf">neural_net</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">||</span><span class="n">ε</span> <span class="o">-</span> <span class="n">ε_theta</span><span class="o">||^</span><span class="mi">2</span>               <span class="c1"># L2损失
</span>    
    <span class="n">θ</span> <span class="o">=</span> <span class="n">θ</span> <span class="o">-</span> <span class="n">lr</span> <span class="o">*</span> <span class="err">∇</span><span class="n">_θ</span> <span class="n">loss</span>                  <span class="c1"># 更新网络参数
</span></code></pre></div></div> <h3 id="生成过程">生成过程</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 初始化
</span><span class="n">x_T</span> <span class="o">~</span> <span class="nc">N</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">I</span><span class="p">)</span>                             <span class="c1"># 从纯高斯噪声开始
</span>
<span class="c1"># 逐步去噪
</span><span class="k">for</span> <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">,...,</span><span class="mi">2</span><span class="p">:</span>                          <span class="c1"># 注意最后一步单独处理
</span>    <span class="n">ε_theta</span> <span class="o">=</span> <span class="nf">neural_net</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>          <span class="c1"># 预测噪声
</span>    <span class="n">μ_t</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">β_t</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x_t</span> <span class="o">-</span> <span class="n">β_t</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">alpha_bar_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">ε_theta</span><span class="p">)</span>  <span class="c1"># 均值更新公式
</span>    <span class="n">z</span> <span class="o">~</span> <span class="nc">N</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">I</span><span class="p">)</span>                            <span class="c1"># 随机高斯噪声
</span>    <span class="n">x_</span><span class="p">{</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">}</span> <span class="o">=</span> <span class="n">μ_t</span> <span class="o">+</span> <span class="nf">sqrt</span><span class="p">(</span><span class="n">β_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">z</span>         <span class="c1"># 采样下一步
</span>
<span class="c1"># 最后一步 t = 1，使用离散解码器生成整数像素
</span><span class="n">μ_1</span> <span class="o">=</span> <span class="nf">neural_net</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">σ_1</span> <span class="o">=</span> <span class="nf">sqrt</span><span class="p">(</span><span class="n">β_1</span><span class="p">)</span>
<span class="n">x_0</span> <span class="o">=</span> <span class="nf">discretized_decoder</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">μ_1</span><span class="p">,</span> <span class="n">σ_1</span><span class="p">)</span>  <span class="c1"># 高斯积分得到 0-255 的像素值
</span>
<span class="k">return</span> <span class="n">x_0</span>                                <span class="c1"># 最终生成图像
</span></code></pre></div></div> <h2 id="接下来要干啥">接下来要干啥</h2> <p>注意到，在对 DDPM 的原理进行介绍的时候，并没有提到 prompt 的问题。这是因为 DDPM 是一个无条件模型，因此不能人为地控制 DDPM 图像的输出。因此产生了 CDDPM。另外，扩散模型的非平衡态热力学的原理看上去也十分有趣。在<del>不</del>遥远的未来，我将尝试对这两个方面进行探究。</p> <h2 id="证明附录">证明附录</h2> <h3 id="变分下界证明">变分下界证明</h3> \[\log p_\theta(x_0)=\log \int p_\theta(x_{0:T})dx_{1:T}=\log \int q(x_{1:T}|x_0)\frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)}dx_{1:T}\] <p>利用 Jensen 不等式：</p> \[f(\mathbb{E}[X]) \le \mathbb{E}[f(X)], \text{where} f\text{ is convex}\] <table> <tbody> <tr> <td>令 $$X=\frac{p_\theta(x_{0:T})}{q(x_{1:T}</td> <td>x_0)}\sim q, f=\log$$，可以得到：</td> </tr> </tbody> </table> \[\log p_\theta(x_0) \ge \mathbb{E}[\log p_\theta(x_{0:T})-\log q(x_{1:T}|x_0)]\] <p>将 \(p_\theta\) 和 \(q\) 展开得到：</p> \[p_\theta(x_{0:T})=p(x_T)\prod_{t=1}^Tp_\theta(x_{t-1}|x_t) \\ q(x_{1:T}|x_0)=\prod_{t=1}^Tq(x_t|x_{t-1})\] <p>将这两项带入上面不等式的右侧，可以得到：</p> \[\log p_\theta(x_{0:T})-\log q(x_{1:T}|x_0) = - \log p(x_T)-\sum_{t=1}^T \log\frac{p_\theta(x_{t-1}|x_t)}{q(x_t|x_{t-1})}\] <p>将结果带入回不等式的右侧，得到我们想要的结果。注意最后不等式的右边是两层期望：先对辅助分布 \(q\) 求期望，再对 \(x_0\) 求期望。</p> <h3 id="其它的">其它的</h3> <p>鸽了鸽了，写不动了(</p>]]></content><author><name></name></author><category term="AI"/><category term="diffusion_model"/><summary type="html"><![CDATA[a brief but strict understanding to DDPM]]></summary></entry><entry><title type="html">notes for advanced C++</title><link href="https://chusi-truth.github.io/blog/2025/notes-for-advanced-cpp/" rel="alternate" type="text/html" title="notes for advanced C++"/><published>2025-09-13T14:00:00+00:00</published><updated>2025-09-13T14:00:00+00:00</updated><id>https://chusi-truth.github.io/blog/2025/notes-for-advanced-cpp</id><content type="html" xml:base="https://chusi-truth.github.io/blog/2025/notes-for-advanced-cpp/"><![CDATA[<h1 id="c-进阶知识">C++ 进阶知识</h1> <p>建议大家到 Github clone 最新的<a href="https://github.com/Chusi-Truth/advanced_Cpp">项目仓库( master 分支)</a>，里面有最新的讲义和示例项目。本次课程会有比较多的实操，因此 clone 仓库后在课上同步进行操作是个不错的选择。</p> <h2 id="从源代码到可执行文件">从源代码到可执行文件</h2> <h3 id="一个-c-程序究竟是怎么跑起来的">一个 C++ 程序究竟是怎么跑起来的</h3> <p>在我们刚开始学习 C++ 的时候，我们运行程序的方法往往是使用 IDE，如 Visual Studio、CLion 等。IDE 会帮助我们完成编译、链接等步骤，最终生成可执行文件。我们只需要点击运行按钮，即可在 IDE 中看到程序的输出。</p> <p>在本节课程中，我们将学习如何手动编译 C++ 程序，了解编译、链接等步骤的具体内容。</p> <h3 id="过程总览">过程总览</h3> <p><img src="../assets/img/notes_cpp/flowChart.png" alt="流程图"/></p> <h3 id="编译工具">编译工具</h3> <p>针对不同的应用场景和平台，各大厂家设计了不同的C++编译工具</p> <ul> <li> <p>MSVC（Microsoft Visual C++）：这是微软开发的一款 C++ 开发工具， Visual Studio 中就内置了 MSVC</p> </li> <li> <p>GCC（GNU Compiler Collection）：GCC 是由 GNU 开发的一套编译工具，支持多种语言。在本节课程中我们使用的编译工具就是 GCC（针对 C 的前端程序为 gcc，针对 C++ 的前端程序为 g++）</p> </li> </ul> <p>在本节课程中，我们使用 wsl 作为运行环境，当然，Windows 的环境也是可以的，你可以通过以下的代码完成 gcc 以及相关工具的安装</p> <p>Linux：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt update
<span class="nb">sudo </span>apt <span class="nb">install </span>build-essential cmake ninja-build
</code></pre></div></div> <p>Windows:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>//请以管理员身份运行 powershell
Set-ExecutionPolicy RemoteSigned <span class="nt">-scope</span> CurrentUser
irm get.scoop.sh | iex

scoop bucket add main
scoop bucket add extras

scoop <span class="nb">install </span>gcc
scoop <span class="nb">install </span>cmake
</code></pre></div></div> <p>当然，在 Windows 环境中你也可以直接到 <a href="https://www.mingw-w64.org/downloads/">mingw</a> 和<a href="https://cmake.org/download/">CMake</a>的官网进行下载，并将 bin 目录添加到环境变量中。</p> <h3 id="预处理preprocessing">预处理(Preprocessing)</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>g++ <span class="nt">-E</span> attack.cpp <span class="nt">-o</span> attack.i
</code></pre></div></div> <p>作用：</p> <ul> <li>处理 #include, #define, #ifdef 等预处理命令。</li> <li>替换宏，展开头文件。</li> </ul> <p>输出：.i 文件（纯C++代码，无预处理指令）</p> <p>示例：../example/case1</p> <h3 id="编译compiling">编译(Compiling)</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>g++ <span class="nt">-S</span> attack.i <span class="nt">-o</span> attack.s
</code></pre></div></div> <p>这一步是编译原理课的重要内容，在这里只进行一些简单的介绍。，</p> <p>编译的五大步骤：</p> <ul> <li>词法分析</li> <li>语法分析</li> <li>语义分析与中间代码生成</li> <li>优化</li> <li>目标代码生成</li> </ul> <h4 id="词法分析">词法分析</h4> <p>在这一步中，词法分析器（Lexer）读取源代码，将其分解为一系列的标记（token）或词法分析单元（lexeme）。这些是编程语言中的基本元素，如关键字，标识符，字面量等。</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>int a = 3 + 5; -&gt; [int] [a] [=] [3] [+] [5] [;]
</code></pre></div></div> <h4 id="语法分析">语法分析</h4> <p>语法分析器使用由词法分析器生成的各个词法单元来创建树形的中间表示。该中间表示给出了词法分析产生的词法单元流的语法结构。一个比较常见的表示方法是语法树(syntax tree)，树中的每一个内部节点表示一个运算，而子节点表示该运算的分量。</p> <p>对于下面的代码：</p> <pre><code class="language-C++">damage=1.5*strength-defence
</code></pre> <p>一颗比较符合直觉的语法分析树长成这样：</p> <p><img src="../assets/img/notes_cpp/syntaxTree1.png" alt="正确的语法分析树"/></p> <p>但是也有可能长成这样：</p> <p><img src="../assets/img/notes_cpp/tree2.png" alt="不正确的语法分析树"/></p> <p>这就是在编译中遇到的二义性问题。</p> <p>对于另外一组代码：</p> <pre><code class="language-C++">if(a&gt;1)
    if(a==2)
        std::cout&lt;&lt;"something1";
    else
        std::cout&lt;&lt;"something2";
</code></pre> <p>同样地，编译器也并不知道 else 应该和哪个 if 配对。</p> <p>为了解决二义性的问题，我们引入上下文无关文法这个概念，并通过合理地设计这个文法，消除由算符优先级和 if-else 悬挂所引起的文法二义性。</p> <h5 id="上下文无关文法">上下文无关文法：</h5> <p>一个上下文无关文法是一个四元组，$ G= {V,\sum,R,S} $，其中 $V$ 是非终止符的集合， $\sum$ 是终止符的集合，$R$ 是产生式规则的集合，$S$ 是开始符号。</p> <p>一个简单的例子： $V={E}$ $\sum={a,b}$ $S \to E, E \to aEb | \epsilon$</p> <p>消除由运算符优先级引起的文法二义性</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;expr&gt;   ::= &lt;expr&gt; "+" &lt;term&gt;
          | &lt;expr&gt; "-" &lt;term&gt;
          | &lt;term&gt;

&lt;term&gt;   ::= &lt;term&gt; "*" &lt;factor&gt;
          | &lt;term&gt; "/" &lt;factor&gt;
          | &lt;factor&gt;

&lt;factor&gt; ::= "(" &lt;expr&gt; ")"
          | number
</code></pre></div></div> <p>消除由 if-else 悬挂引起的文法二义性</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;stmt&gt;           ::= &lt;matched_stmt&gt; | &lt;unmatched_stmt&gt;

&lt;matched_stmt&gt;   ::= "if" "(" &lt;expr&gt; ")" &lt;matched_stmt&gt; "else" &lt;matched_stmt&gt;
                  | &lt;other_stmt&gt;

&lt;unmatched_stmt&gt; ::= "if" "(" &lt;expr&gt; ")" &lt;stmt&gt;
                  | "if" "(" &lt;expr&gt; ")" &lt;matched_stmt&gt; "else" &lt;unmatched_stmt&gt;
</code></pre></div></div> <h4 id="语义分析与中间代码生成">语义分析与中间代码生成</h4> <h5 id="语义分析semantic-analysis">语义分析（Semantic Analysis）</h5> <p>检查语义是否正确，确保程序含义合理 常见检查内容：</p> <ul> <li>类型检查（int ≠ string）</li> <li>变量是否已声明</li> <li>函数参数匹配</li> <li>作用域合法性</li> <li>构建符号表（Symbol Table）</li> </ul> <pre><code class="language-C++">int a = 3 + "hello";
</code></pre> <h5 id="中间代码生成intermediate-code-generation">中间代码生成（Intermediate Code Generation）</h5> <p>将语义正确的代码转换为中间表示（IR） 典型形式：三地址码（Three Address Code</p> <pre><code class="language-C++">// 源码：
a = b + c * d;
</code></pre> <div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">//</span> <span class="err">三地址码：</span>
<span class="py">t1</span> <span class="p">=</span> <span class="s">c * d</span>
<span class="py">t2</span> <span class="p">=</span> <span class="s">b + t1</span>
<span class="py">a</span> <span class="p">=</span> <span class="s">t2</span>
</code></pre></div></div> <h4 id="优化optimization">优化（Optimization）</h4> <h5 id="目标">目标：</h5> <ul> <li>提高执行效率</li> <li>减少资源消耗</li> </ul> <h5 id="优化类型">优化类型：</h5> <ul> <li>中间代码优化（平台无关）</li> <li>目标代码优化（平台相关）</li> </ul> <h5 id="常见优化技术">常见优化技术：</h5> <table> <thead> <tr> <th>优化名</th> <th>示例前</th> <th>示例后</th> </tr> </thead> <tbody> <tr> <td>常量折叠</td> <td><code class="language-plaintext highlighter-rouge">x = 3 + 5;</code></td> <td><code class="language-plaintext highlighter-rouge">x = 8;</code></td> </tr> <tr> <td>死代码删除</td> <td><code class="language-plaintext highlighter-rouge">int a = 5; return 1;</code></td> <td><code class="language-plaintext highlighter-rouge">return 1;</code></td> </tr> <tr> <td>公共子表达式消除</td> <td><code class="language-plaintext highlighter-rouge">a = b + c; d = b + c;</code></td> <td><code class="language-plaintext highlighter-rouge">t = b + c; a = t; d = t;</code></td> </tr> <tr> <td>循环不变代码外提</td> <td>在循环中重复计算</td> <td>提前到循环外</td> </tr> <tr> <td>函数内联</td> <td><code class="language-plaintext highlighter-rouge">call foo()</code></td> <td>展开 <code class="language-plaintext highlighter-rouge">foo</code> 函数体</td> </tr> </tbody> </table> <p><img src="../assets/img/notes_cpp/spiderman.jpg" alt="C++梗图"/></p> <h4 id="目标代码生成target-code-generation">目标代码生成（Target Code Generation）</h4> <h5 id="目标-1">目标：</h5> <p>将优化后的中间代码转换为平台相关的汇编代码或机器代码</p> <p>示例： 三地址码：</p> <div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="py">t1</span> <span class="p">=</span> <span class="s">c * d</span>
<span class="py">t2</span> <span class="p">=</span> <span class="s">b + t1</span>
<span class="py">a</span> <span class="p">=</span> <span class="s">t2</span>
</code></pre></div></div> <p>对应 x86 汇编：</p> <pre><code class="language-asm">mov eax, [c]
imul eax, [d]
add eax, [b]
mov [a], eax
</code></pre> <h3 id="汇编">汇编</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>g++ <span class="nt">-c</span> attack.s <span class="nt">-o</span> attack.o
</code></pre></div></div> <p>汇编这一步将编译器生成的中间代码（汇编代码）翻译为机器码（一种包含机器指令的二进制格式文件），但尚未完成链接。</p> <p>.o 生成的文件不是人类可读的，但是如果你实在是好奇里面究竟有什么，可以在终端输入如下的指令：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>objdump <span class="nt">-d</span> attack.o
</code></pre></div></div> <p>它会把机器码进行反汇编，输出的格式应该类似于：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>test.o:     file format pe-x86-64


Disassembly of section .text:

0000000000000000 &lt;main&gt;:
   0:   55                      push   %rbp
   1:   48 89 e5                mov    %rsp,%rbp
   4:   48 83 ec 30             sub    $0x30,%rsp
   8:   e8 00 00 00 00          call   d &lt;main+0xd&gt;
   d:   c7 45 fc 01 00 00 00    movl   $0x1,-0x4(%rbp)
  14:   83 7d fc 01             cmpl   $0x1,-0x4(%rbp)
  18:   75 16                   jne    30 &lt;main+0x30&gt;
  1a:   48 8d 15 00 00 00 00    lea    0x0(%rip),%rdx        # 21 &lt;main+0x21&gt;
  21:   48 8b 05 00 00 00 00    mov    0x0(%rip),%rax        # 28 &lt;main+0x28&gt;
  28:   48 89 c1                mov    %rax,%rcx
  2b:   e8 00 00 00 00          call   30 &lt;main+0x30&gt;
  30:   83 7d fc 02             cmpl   $0x2,-0x4(%rbp)
  34:   75 18                   jne    4e &lt;main+0x4e&gt;
  36:   48 8d 15 0b 00 00 00    lea    0xb(%rip),%rdx        # 48 &lt;main+0x48&gt;
  3d:   48 8b 05 00 00 00 00    mov    0x0(%rip),%rax        # 44 &lt;main+0x44&gt;
  44:   48 89 c1                mov    %rax,%rcx
  47:   e8 00 00 00 00          call   4c &lt;main+0x4c&gt;
  4c:   eb 16                   jmp    64 &lt;main+0x64&gt;
  4e:   48 8d 15 16 00 00 00    lea    0x16(%rip),%rdx        # 6b &lt;main+0x6b&gt;
  55:   48 8b 05 00 00 00 00    mov    0x0(%rip),%rax        # 5c &lt;main+0x5c&gt;
  5c:   48 89 c1                mov    %rax,%rcx
  5f:   e8 00 00 00 00          call   64 &lt;main+0x64&gt;
  64:   b8 00 00 00 00          mov    $0x0,%eax
  69:   48 83 c4 30             add    $0x30,%rsp
  6d:   5d                      pop    %rbp
  6e:   c3                      ret
  6f:   90                      nop
</code></pre></div></div> <h3 id="链接">链接</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>g++ main.o foo.o <span class="nt">-o</span> program
</code></pre></div></div> <p>链接将多个目标文件和库组织成一个完整的可执行文件或共享库。</p> <p>示例：../example/case2</p> <h4 id="静态链接">静态链接</h4> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>g++ main.o foo.o <span class="nt">-o</span> program
</code></pre></div></div> <p>所有的代码在链接阶段合并成一个单独的大文件，运行的时候无需依赖外部文件库。</p> <ul> <li>优点：部署简单，运行稳定</li> <li>缺点：文件体积大，重复冗余，不利于更新</li> </ul> <h4 id="动态链接">动态链接</h4> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>g++ main.o <span class="nt">-o</span> program <span class="nt">-lfoo</span>
</code></pre></div></div> <p>最终生成的可执行文件中包含对动态库的引用，例如 windows 中的 .dll 和 Linux 中的 .so</p> <ul> <li> <p>优点：节省空间，多个程序可以共享库，易于更新</p> </li> <li> <p>缺点：运行的时候需要依赖外部库，存在 <a href="https://zh.wikipedia.org/wiki/%E7%9B%B8%E4%BE%9D%E6%80%A7%E5%9C%B0%E7%8B%B1">依赖地狱</a></p> </li> </ul> <h4 id="静态库">静态库</h4> <p>代码被复制到最终的可执行文件中</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>g++ <span class="nt">-c</span> math.cpp        <span class="c"># 编译成目标文件 math.o</span>
ar rcs libmath.a math.o  <span class="c"># 打包成静态库</span>
g++ main.cpp <span class="nt">-L</span><span class="nb">.</span> <span class="nt">-lmath</span> <span class="nt">-o</span> main  <span class="c"># 链接静态库</span>
</code></pre></div></div> <p>rcs：这是一组参数，r代表 将 math.o 加入库中，c代表创建库文件，s代表生成符号索引。 -L. 表示在当前目录下寻找库文件 -lxxx 表示链接 libxxx.a</p> <h4 id="动态库">动态库</h4> <p>可执行文件运行时加载库文件</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>g++ <span class="nt">-fPIC</span> <span class="nt">-shared</span> math.cpp <span class="nt">-o</span> libmath.dll  <span class="c"># 创建动态库</span>
g++ main.cpp <span class="nt">-L</span><span class="nb">.</span> <span class="nt">-lmath</span> <span class="nt">-o</span> main           <span class="c"># 链接动态库（运行时需要 libmath.so）</span>
</code></pre></div></div> <p>-fPIC 在 Linux 系统中用于生成可以在任意内存地址加载(位置无关代码)的共享库，对于 Windows系统不是必须的。</p> <h4 id="examplecase2-示例">../example/case2 示例</h4> <p>我们机器人的行为通过 behavior.h 头文件中的函数进行控制，通过动态链接，我们可以更新头文件，但是无需重新编译其它机器人的源代码。</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 编译动态库（Windows 下生成 .dll，Linux 下生成 .so）</span>
g++ <span class="nt">-fPIC</span> <span class="nt">-shared</span> src/behavior.cpp <span class="nt">-o</span> libbehavior.so   <span class="c"># Linux</span>
g++ <span class="nt">-fPIC</span> <span class="nt">-shared</span> src/act.cpp <span class="nt">-o</span> libact.so   <span class="c"># Linux</span>
<span class="c"># 编译主程序并链接动态库</span>
g++ src/run.cpp <span class="nt">-Iinclude</span> <span class="nt">-o</span> run <span class="nt">-L</span><span class="nb">.</span> <span class="nt">-lbehavior</span> <span class="nt">-Wl</span>,-rpath<span class="o">=</span><span class="nb">.</span>
</code></pre></div></div> <h3 id="管理大型项目的构建makefile-与-cmake">管理大型项目的构建：Makefile 与 Cmake</h3> <h2 id="大型项目的构建">大型项目的构建</h2> <p>使用 g++ 构建项目时，在链接阶段 对源文件或目标文件的顺序有时有要求。例如，如果 firstFile.cpp 中定义了函数 foo，而 secondFile.cpp 中调用了该函数，那么链接命令中 firstFile.o 应出现在 secondFile.o 之后：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>g++ secondFile.o firstFile.o <span class="nt">-o</span> program
</code></pre></div></div> <p>此外，在构建大型项目时，由于源文件之间存在复杂的依赖关系（例如头文件修改会影响多个 .cpp 文件），手动判断哪些文件需要重新编译几乎不可能。使用 g++ 时通常只能粗暴地全量重新编译：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// 下面的执行在../example/case3 下执行
//创建一堆没有用的头文件，模拟大项目的高耗时
./dummyCreator.sh
//Win
Measure-Command <span class="o">{</span> g++ src/<span class="k">*</span>.cpp <span class="nt">-Iinclude</span> <span class="nt">-o</span> run.exe <span class="o">}</span>
//Linux
<span class="nb">time </span>g++ src/<span class="k">*</span>.cpp <span class="nt">-Iinclude</span> <span class="nt">-o</span> run
</code></pre></div></div> <p>这种方式虽简单，但随着项目体积增大，将极大影响构建效率。 因此，借助自动化构建工具如 Make 或 CMake，可以根据文件的修改时间自动判断依赖关系，只编译必要的文件，大幅缩短构建时间，提升开发效率。</p> <h3 id="makefile">Makefile</h3> <p>Makefile：经典的自动化构建系统 Make 是 Unix 系统中最常用的构建工具之一。通过编写 Makefile，开发者可以精确描述各个目标文件的依赖关系和构建规则。当某个源文件发生变动时，make 只会重新编译受影响的部分，而不是整个项目。</p> <p>例如，在一个包含多个源文件的项目中，如果只修改了 act.cpp，使用 make 时只会重新编译该文件及与之相关的目标文件，而不是所有 .cpp 文件。这种 增量编译 能显著缩短构建时间，尤其在包含上千个文件的大型工程中效果尤为明显。</p> <p>此外，Makefile 语法灵活，支持变量、条件判断、自动推导规则等机制，可以实现复杂的构建流程控制。</p> <p>然而，Makefile 的可读性较差（示例见下），在开发过程中一般不是手动编写的，而是由构建工具自动生成的。如 Cmake</p> <div class="language-makefile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 编译器和参数
</span><span class="nv">CXX</span> <span class="o">:=</span> g++
<span class="nv">CXXFLAGS</span> <span class="o">:=</span> <span class="nt">-Iinclude</span> <span class="nt">-std</span><span class="o">=</span>c++17 <span class="nt">-Wall</span> <span class="nt">-ftemplate-depth</span><span class="o">=</span>11000

<span class="c"># 源文件和目标文件
</span><span class="nv">SRC</span> <span class="o">:=</span> <span class="p">$(</span>wildcard src/<span class="k">*</span>.cpp<span class="p">)</span>
<span class="nv">OBJ</span> <span class="o">:=</span> <span class="p">$(</span>SRC:.cpp<span class="o">=</span>.o<span class="p">)</span>

<span class="c"># 最终可执行文件名
</span><span class="nv">TARGET</span> <span class="o">:=</span> run.exe

<span class="c"># 默认目标
</span><span class="nl">all</span><span class="o">:</span> <span class="nf">$(TARGET)</span>

<span class="c"># 链接
</span><span class="nl">$(TARGET)</span><span class="o">:</span> <span class="nf">$(OBJ)</span>
    <span class="err">$(CXX)</span> <span class="err">$(OBJ)</span> <span class="err">-o</span> <span class="err">$@</span>

<span class="c"># 编译每个 .cpp 为 .o
</span><span class="nl">src/%.o</span><span class="o">:</span> <span class="nf">src/%.cpp</span>
    <span class="err">$(CXX)</span> <span class="err">$(CXXFLAGS)</span> <span class="err">-c</span> <span class="err">$&lt;</span> <span class="err">-o</span> <span class="err">$@</span>

<span class="c"># 清理构建产物
</span><span class="nl">clean</span><span class="o">:</span>
    <span class="err">del</span> <span class="err">/Q</span> <span class="err">src\*.o</span> <span class="err">$(TARGET)</span> <span class="err">2&gt;nul</span> <span class="err">||</span> <span class="err">true</span>

<span class="c"># 伪目标，避免和文件重名
</span><span class="nl">.PHONY</span><span class="o">:</span> <span class="nf">all clean</span>
</code></pre></div></div> <h3 id="cmake">CMake</h3> <h4 id="cmakeliststxt">CMakelists.txt</h4> <p>CMakeLists.txt 是 CMake 的核心配置文件，用于描述项目的构建规则和设置。每个 CMake 项目根目录下必须包含一个 CMakeLists.txt，子目录也可以包含各自的 CMakeLists.txt，用于模块化管理。</p> <h5 id="基本结构示例">基本结构示例</h5> <div class="language-cmake highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 指定最低CMake版本要求</span>
<span class="nb">cmake_minimum_required</span><span class="p">(</span>VERSION 3.12<span class="p">)</span>

<span class="c1"># 定义项目名称和使用语言</span>
<span class="nb">project</span><span class="p">(</span>DemoProject LANGUAGES CXX<span class="p">)</span>

<span class="c1"># 设置C++标准</span>
<span class="nb">set</span><span class="p">(</span>CMAKE_CXX_STANDARD 17<span class="p">)</span>
<span class="nb">set</span><span class="p">(</span>CMAKE_CXX_STANDARD_REQUIRED ON<span class="p">)</span>

<span class="c1"># 包含头文件目录</span>
<span class="nb">include_directories</span><span class="p">(</span>include<span class="p">)</span>

<span class="c1"># 收集源文件</span>
<span class="nb">file</span><span class="p">(</span>GLOB SOURCES src/*.cpp<span class="p">)</span>

<span class="c1"># 添加可执行文件目标</span>
<span class="nb">add_executable</span><span class="p">(</span>run <span class="si">${</span><span class="nv">SOURCES</span><span class="si">}</span><span class="p">)</span>

<span class="c1"># 添加编译选项（可选）</span>
<span class="nb">target_compile_options</span><span class="p">(</span>run PRIVATE -Wall -Wextra<span class="p">)</span>
</code></pre></div></div> <h5 id="分目录项目管理">分目录项目管理</h5> <div class="language-cmake highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 添加子目录，递归处理子目录中的CMakeLists.txt</span>
<span class="nb">add_subdirectory</span><span class="p">(</span>src<span class="p">)</span>
</code></pre></div></div> <h5 id="编译选项和宏定义">编译选项和宏定义</h5> <div class="language-cmake highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">target_compile_definitions</span><span class="p">(</span>run PRIVATE DEBUG_MODE<span class="p">)</span>
<span class="nb">target_compile_options</span><span class="p">(</span>run PRIVATE -O2 -Wall<span class="p">)</span>
</code></pre></div></div> <h5 id="变量与条件判断">变量与条件判断</h5> <div class="language-cmake highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">if</span><span class="p">(</span>WIN32<span class="p">)</span>
  <span class="nb">message</span><span class="p">(</span>STATUS <span class="s2">"Building on Windows"</span><span class="p">)</span>
<span class="nb">elseif</span><span class="p">(</span>UNIX<span class="p">)</span>
  <span class="nb">message</span><span class="p">(</span>STATUS <span class="s2">"Building on Unix/Linux"</span><span class="p">)</span>
<span class="nb">endif</span><span class="p">()</span>
</code></pre></div></div> <h5 id="链接第三方库">链接第三方库</h5> <div class="language-cmake highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">set</span><span class="p">(</span>CMAKE_PREFIX_PATH <span class="s2">"/path/to/custom/lib/cmake"</span><span class="p">)</span>
<span class="nb">find_package</span><span class="p">(</span>SomeLib REQUIRED<span class="p">)</span>
<span class="nb">target_link_libraries</span><span class="p">(</span>run PRIVATE SomeLib::SomeLib<span class="p">)</span>
</code></pre></div></div> <h4 id="1-使用-unix-makefiles-生成器">1. 使用 Unix Makefiles 生成器</h4> <p>这是 CMake 默认在类 Unix 系统上的生成器。 会生成传统的 Makefile 文件，使用 make 命令进行构建。 适合习惯用 make 的用户，支持丰富的命令行参数。</p> <h5 id="典型流程">典型流程</h5> <p>在项目根目录执行：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cmake <span class="nt">-G</span> <span class="s2">"Unix Makefiles"</span> <span class="nt">-S</span> <span class="nb">.</span> <span class="nt">-B</span> build
<span class="c"># 进入构建目录，执行构建</span>
make <span class="nt">-C</span> build
<span class="c"># 运行程序</span>
./build/bin/run
</code></pre></div></div> <h4 id="2-使用-ninja-生成器">2. 使用 Ninja 生成器</h4> <p>Ninja 是一个专门设计用于快速构建的小型构建系统。 CMake 生成 build.ninja 文件，使用 ninja 命令构建。 速度快，支持更细粒度的增量构建。</p> <h5 id="典型流程-1">典型流程</h5> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 生成 Ninja 构建文件</span>
cmake <span class="nt">-G</span> Ninja <span class="nt">-S</span> <span class="nb">.</span> <span class="nt">-B</span> build
<span class="c"># 构建项目</span>
cmake <span class="nt">--build</span> build <span class="nt">--</span> <span class="nt">--quiet</span>
<span class="c"># 运行程序</span>
./build/bin/run
</code></pre></div></div> <p>或者直接使用 ninja 命令：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ninja <span class="nt">-C</span> build <span class="nt">--quiet</span>
</code></pre></div></div> <h4 id="3-注意事项">3. 注意事项</h4> <p>构建目录只能对应一种生成器，切换生成器前要清理旧构建目录或使用新目录。 在 WSL 里可用的生成器还有 Ninja、Unix Makefiles 及其它（但最常用的是这两种）。 Windows 原生环境常用的生成器是 Visual Studio。</p> <h2 id="作业">作业</h2> <p>见 assignment/hw.md</p> <h2 id="参考资料">参考资料</h2> <ul> <li><a href="https://cloud.tsinghua.edu.cn/d/ca958715a8ea4e91a0ac/files/?p=%2F%E8%AE%B2%E4%B9%89%2F5_C%2B%2B%E8%BF%9B%E9%98%B6%E7%9F%A5%E8%AF%86%E4%BB%8B%E7%BB%8D.pdf">往年暑培讲义</a></li> <li><a href="https://cmake.org/documentation/">CMake 官方文档</a></li> <li><a href="https://github.com/ttroy50/cmake-examples">cmake-examples</a> 该 GitHub 仓库中有很多开箱即用的 CMake 实例。</li> <li><a href="https://www.zhihu.com/question/461953861/answer/1914452432">为什么编译 c/c++要用 makefile，而不是直接用 shell 呢？</a> 这篇博文详细地阐述了使用 makefile 的动机和意义（\xfgg/）。</li> <li><a href="https://seisman.github.io/how-to-write-makefile/introduction.html">跟我一起写 Makefile</a> Makefile 教程。从中大家也可以看出 Makefile 的语法十分不友好…</li> <li><a href="https://zh.z-library.sk/book/5668399/1c0fd2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%9B%E4%B9%A6%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC2%E7%89%88.html">编译原理</a></li> </ul>]]></content><author><name></name></author><category term="cs"/><category term="C++"/><summary type="html"><![CDATA[Notes on the C++ section of the summer training program]]></summary></entry><entry><title type="html">understanding topological space</title><link href="https://chusi-truth.github.io/blog/2025/understanding-topological-space/" rel="alternate" type="text/html" title="understanding topological space"/><published>2025-09-13T14:00:00+00:00</published><updated>2025-09-13T14:00:00+00:00</updated><id>https://chusi-truth.github.io/blog/2025/understanding-topological-space</id><content type="html" xml:base="https://chusi-truth.github.io/blog/2025/understanding-topological-space/"><![CDATA[<h1 id="一个对拓扑空间的简单理解">一个对拓扑空间的简单理解</h1> <h2 id="总要有一些学习的原因">总要有一些学习的原因</h2> <p>对测度论的认识起源于刚学微积分的时候，教材中提到了一个叫做“零测度集”的东西。后来在上概率论与数理统计的时候，有一次在做作业的时候遇到了一个说不清道不明的概率构造，只能迷迷糊糊地觉得和概率空间的划分有关系。之后莫名奇妙地了解到了测度这一概念，知道了测度是现代概率论的基石。于是暑假抱着“与其摆烂不如学点有意思的东西”的想法，开始自学测度论。然而前置知识就直接把我干趴下了：点集拓扑，度量空间，拓扑空间，可数空间，T空间……笔记记了不少，但是学完就忘的也不少。因此决定使用费曼学习法，尝试一个一个把晦涩的概念讲清楚。下面有请本系列的第一个数学概念：拓扑空间。</p> <h2 id="拓扑空间的起源">拓扑空间的起源</h2> <p>拓扑空间实际上是对度量空间的拓展。通过度量空间定义的距离，我们可以引入更多复杂的概念，但是度量空间对距离的定义是带有特殊性的，为了能够在“任意的集合上”，引入一种不依赖具体距离的“邻近”结构，从而更加一般地研究连续性、收敛性等性质，拓扑空间被自然地引入了。</p> <blockquote> <p>[!tip]</p> <p>度量空间实际上是一个比较显然的定义。它定义了一个空间中两点之间的距离，例如我们熟知的 Manhattan Distance 和 Euclidean Distance，通过定义距离，度量空间进而定义了开集，闭集，邻域，收敛等概念。然而，如果空间中的元素从单点变成了更加复杂的东西，例如函数，那么距离这个概念就很难定义了。</p> </blockquote> <p>举出一个比较简单的例子：$\bold{R}^1$ 空间中点列收敛到某一点，一般可以被形式化表述为： \(\forall \epsilon, \exist N, s.t. \forall n&gt;N, |x_n-x|&lt;\epsilon\) 在点列收敛性的形式化定义中，“临近”结构表现在 $|x_n-x|&lt;\epsilon$ 中。在这里我们通过 Euclidean Distance 描述临近性。不难发现所谓的”临近性”都是针对于某一点而讨论的。因此，为了避免距离定义的特殊性，我们可以选择直接绕过定义距离，转而选择直接定义点的临近。</p> <blockquote> <p>[!tip]</p> <table> <tbody> <tr> <td>在尝试避免定义距离，而是直接定义临近性的过程中，我们注意到，开集是一个无法回避的定义，正如上例中 $</td> <td>x_n-x</td> <td>&lt;\epsilon$ 实际上表示了一个开球。因此，在定义拓扑空间的时候，我们从对开集定义入手。</td> </tr> </tbody> </table> </blockquote> <h2 id="对拓扑空间形式化定义的理解">对拓扑空间形式化定义的理解</h2> <p>拓扑空间的形式化定义可以如下表述：</p> <blockquote> <p>[!note]</p> <p>称非空集合 $\bold{X}$ 的一个子集族 $\mathcal{T}$ 为 $\bold{X}$ 上的一个拓扑，如果它满足下&gt; 面三个条件：</p> <ul> <li>$\empty \in \mathcal{T}, \bold{X} \in \mathcal{T}$</li> <li>if ${G_\alpha, \alpha \in \Lambda}$, then $\cup_{\alpha \in \Lambda}G_\alpha \in \mathcal{T}$</li> <li>if $G_1, G_2 \in \mathcal{T}$, then $G_1 \cap G_2 \in \mathcal{T}$</li> </ul> </blockquote> <p>上面的三个条件实际上定义了空间 $\bold X$ 中什么样的集合是开集。第一个条件定义了全集和空集都是开集；第二个条件定义了开集的任意并也是开集；第三个条件定义了开集的有限交也是开集。这三条定义和我们对开集的认知是一致的。</p> <blockquote> <p>[!tip]</p> <p>对于定义中的第三条，可以举出这样一个反例： \(\lim_{n \to \infty} \bigcap_n (-\frac{1}{n},\frac{1}{n}) =\{0\}\) 显然一个单点集是闭集而不是开集。因此第三条规定的是有限交而不是任意交。</p> </blockquote> <h2 id="使用拓扑空间拓展定义">使用拓扑空间拓展定义</h2> <p>在定义拓扑空间后，我们可以继续拓展其它定义：</p> <h3 id="邻域">邻域</h3> <blockquote> <p>[!note]</p> <p>邻域：如果 $x$ 满足以下条件，就称 $N$ 为 $x$ 的一个邻域。 \(x \in N \sub \bold X, \exist U \in \mathcal{T}, x \in U \sub N\) $x$ 的开邻域：包含点 $x$ 的开集。</p> <p>$x$ 的邻域系：$x$ 所有邻域组成的集族，记为 $\mathcal{N}(x)$</p> </blockquote> <p>在对邻域的定义中不难发现，邻域的定义要宽于开集，只要一个集合包含 $x$ 的一个开邻域，那么这个集合就是邻域。</p> <h3 id="点列极限">点列极限</h3> <blockquote> <p>[!note]</p> <p>继续以上面点列极限的定义作为例子。在拓扑空间中，点列极限的定义应该改为： \(\forall U \in \mathcal{N}(x),\exist N,s.t.\forall n&gt;N, x_n \in U\)</p> </blockquote> <p>在定义中对邻域的选择，实际上就是在度量空间中先选择 $\epsilon$ ，再诱导出一个开球的过程。对邻域选择的任意性，实际上保证了开集的任意小。</p> <h3 id="聚点">聚点</h3> <blockquote> <p>[!note]</p> <p>称 $x$ 为 $A\sub X$ 的聚点，如果： \(\forall N \in \mathcal{N}(x), N\cap(A - \{x\})\ne\empty\)</p> </blockquote> <p>也就是说，$x$ 的任意小邻域中都含有 A 中的元素。</p> <h3 id="导集">导集</h3> <blockquote> <p>[!note]</p> <p>称由 A 的所有聚点组成的集合为 A 的导集，记为 $A^d$</p> </blockquote> <h3 id="闭包">闭包</h3> <blockquote> <p>[!note]</p> <p>称包含 A 的最小闭集为 A 的闭包，记作 $\bar{A}$</p> </blockquote> <p>实际上有 $\bar{A}=A\cup A^d$</p> <h2 id="总结">总结</h2> <p>由度量空间诱导出的开集依赖于度量空间中的度量方式。为了解决这一依赖性，拓扑空间直接定义开集，并以此定义更上层的概念。实际上，拓扑空间还有基，连续映射等等可以介绍（已加入鸽子日程表）。</p> <h2 id="参考资料">参考资料</h2> <p><a href="https://zhuanlan.zhihu.com/p/470295420">拓扑空间的理解 - 知乎</a></p> <p><a href="https://zh.z-library.sk/book/28300011/d48e26/测度论基础与高等概率论-上册.html">测度论基础与高等概率论 上册</a></p>]]></content><author><name></name></author><category term="math"/><category term="measure"/><category term="theory"/><summary type="html"><![CDATA[a brief understanding to topological space]]></summary></entry><entry><title type="html">a post with math test</title><link href="https://chusi-truth.github.io/blog/2025/qwqlfulyou/" rel="alternate" type="text/html" title="a post with math test"/><published>2025-09-13T11:39:00+00:00</published><updated>2025-09-13T11:39:00+00:00</updated><id>https://chusi-truth.github.io/blog/2025/qwqlfulyou</id><content type="html" xml:base="https://chusi-truth.github.io/blog/2025/qwqlfulyou/"><![CDATA[<h1 id="ddpm扩散模型梦开始的地方">DDPM：扩散模型梦开始的地方</h1> <h2 id="为什么是-ddpm">为什么是 DDPM</h2> <p>答案很简单：因为最近扩散模型很火，因此为了蹭上一波热度开始了解扩散模型的方向。DDPM作为一个比较经典的扩散模型，具有较为复杂的数学推导。在学习过程中容易出现理论与代码实践切割的情况。因此这篇文章希望能够统一地介绍DDPM的数学原理以及具体的代码实现。</p> <h2 id="直观感受">直观感受</h2> <h3 id="源自非平衡态热力学的启发">源自非平衡态热力学的启发</h3> <p>DDPM的核心思想是模仿物理世界中粒子扩散的过程。例如，一滴墨水在水中逐渐散开，最终均匀分布，这是一个从有序到无序的过程。DDPM通过学习这个过程的逆过程，从完全无序的噪声中逐步恢复出有序、清晰的图案。</p> <h4 id="前向扩散过程">前向扩散过程</h4> <p>这个过程是非平衡热力学中的熵增过程，系统从有序变得无序。在DDPM中，这个过程表现为一张图像和一个高斯噪声按照一定比例混合，形成新的图像，经过多次上述操作后，我们可以得到一张约为完全噪音的图像。</p> <h4 id="反向去噪过程">反向去噪过程</h4> <p>这个过程是前向扩散过程的逆过程，系统从无序变得有序。在DDPM中，这个过程表现为，给模型一张带有噪音的图像，模型尝试生成其中噪音的部分并将其去除。给模型一张纯噪音图像，经过多次去噪，我们就有可能得到一张清晰的图像。</p> <h2 id="数学原理">数学原理</h2> <p>针对上述直观的过程，我们下面进行较为严格的数学推导。</p> <h3 id="加噪与去噪">加噪与去噪</h3> <p>我们首先定义时间步 \(T\) ，这表示我们总共需要加噪，去噪 \(T\) 次之后才能得到一张完全的噪声图像或生成图像。特别地，我们使用 \(x_t\) 表示目前的图像被加噪了多少次。\(x_0\) 表示这是一张没有经过加噪的正常图像，\(x_T\) 表示这是一张经过 \(T\) 次加噪后得到的一张噪声图像。</p> <p>加噪过程的每一步，都只与当前图像有关，而与再之前的图像无关。这说明，加噪过程是一个马尔科夫链。去噪过程我们也假设可以写成一个马尔科夫链。</p> <p>对于加噪过程，DDPM定义为：</p> \[q(x_t|x_{t-1}):=\mathcal{N}(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_t \mathbf{I})\] <p>对于去噪过程，DDPM 定义为：</p> \[p_\theta(x_{t-1}|x_t):=\mathcal{N}（x_{t-1};\mu_\theta(x_t,t),\Sigma_\theta(x_t,t)) \\\] <p>另外，还有加噪轨迹和去噪轨迹：</p> \[q(x_{1:T}|x_0):=\prod_{t=1}^Tq(x_t|x_{t-1}) \\p_\theta(x_{0:T}):=p(x_T)\prod_{t=1}^Tp_\theta(x_{t-1}|x_t)\] <blockquote> <p>[!note]</p> <p>其中，\(\{\beta_t\}\) 是一族超参数，不需要模型学习。去噪过程中高斯分布的均值和方差与图像和时间步相关，在具体实现的时候。DDPM 将 \(\Sigma_\theta\) 设为了一组只和时间步相关的常数 \(\sigma_t^2\)</p> </blockquote> <h3 id="损失函数">损失函数</h3> <p>由于我们从噪声生成图像的过程中，希望能够生成给定的图像 \(x_0\) ，因此我们要计算 \(p_\theta(x_0)\) :</p> \[p_\theta(x_0)=\int p_\theta(x_{0:T})dx_{1:T} \\ p_\theta(x_{0:T}):=p(x_T)\prod_{t=1}^{T}p_\theta(x_{t-1}|x_t) \\ p_\theta(x_{t-1}|x_t):=\mathcal{N}(x_{t-1};\mu_\theta(x_t,t),\Sigma_\theta(x_t,t))\] <p>模型学习的分布应当尽量与数据集中的分布一致，而我们可以把数据集中每一个图像看作一类。这样，我们可以把 DDPM 看作一个分类模型（虽然数据是连续的）：给定一个高斯噪声，通过不断去噪得到它正确的分类（图像结果），因此我们可以用交叉熵作为损失函数。</p> \[\mathbb{E}[-\log p_\theta(x_0)]\] <p>然而，在实际过程中我们很难计算 \(p_\theta(x_0)\) ， 因此通过变分推断近似解决： $$</p> <table> <tbody> <tr> <td>\mathbb{E}[-\log p_\theta(x_0)] \le \mathbb{E}<em>{x_0,q}[-\log\frac{p</em>\theta(x_{0:T})}{q(x_{1:T}</td> <td>x_0)}]</td> </tr> </tbody> </table> <p>\=\mathbb{E}<em>{x_0,q}[-\log p(x_T)-\sum</em>{t \ge 1}\log\frac{p_\theta(x_{t-1}|x_t)}{q(x_t|x_{t-1})}]=:L $$</p> <blockquote> <p>[!note]</p> <table> <tbody> <tr> <td>观察不等式的两边，我们注意到，通过变分推断，我们避免了计算难以解析的高维积分，而是通过改为计算 $$\log\frac{p_\theta(x_{0:T})}{q(x_{1:T}</td> <td>x_0)}\(对分布\)q(x_{1:T</td> <td>x_0})\(的期望来计算\)\log p_\theta(x_0)$$ 的下界。</td> </tr> </tbody> </table> <p>因此，需要注意损失函数实际上要最小化的是两层期望。</p> <p><a href="#证明附录">详细证明见附录</a></p> </blockquote> <p>通过变换，\(L\) 可以被重写为如下形式：</p> \[\mathbb{E}_{x_0,q}[D_{KL}(q(x_T|x_0)||p(x_T))+\sum_{t&gt;1}D_{KL}(q(x_{t-1}|x_t,x_0)||p_\theta(x_{t-1}|x_t)) \\-\log p_\theta(x_0|x_1)]\] <p>期望中从左到右的三项分别称之为 \(L_T, L_{t-1}, L_0\)。这样写的好处在于，我们可以对模型训练的目标有一个清晰而直观的理解：</p> <p>\(L_T\) 试图让加噪生成的噪声图像的分布尽量接近于生成图像时采样噪声的分布。在 DDPM 中，由于 \(q\) 和 \(p(x_T)\) 实际上都是已知的，因此 \(L_T\) 是一个可以忽略的常数项。</p> <p>\(L_{t-1}\) 试图让可学习的分布 \(p_\theta\) 去尽量逼近加噪过程的逆过程。这实际上就是在学习预测噪声。</p> <p>\(L_0\) 实际上就是负对数化似然。</p> <blockquote> <p>[!note]</p> <p>KL 散度是信息论中的一个概念，用来衡量两个分布之间的差异。 \(D_{KL}(P||Q)=\int P(X)\log \frac{P(X)}{Q(X)}dx\) 性质：</p> <ul> <li>非负性：取零时，当且仅当 \(P=Q\)</li> <li> <table> <tbody> <tr> <td>不对称性：$$D_{KL}(P</td> <td> </td> <td>Q) \ne D_{KL}(Q</td> <td> </td> <td>P)$$</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>期望形式：$$D_{KL}(P</td> <td> </td> <td>Q)=\mathbb{E}[\log P(x)-\log Q(x)]$$</td> </tr> </tbody> </table> </li> </ul> </blockquote> <blockquote> <p>[!important]</p> <p>一个令人疑惑的点是：\(L_0\) 实际上也是预测噪声的一部分，为什么不能并入 \(L_{t-1}\) 呢？</p> <p>问题在于，\(t=1\) 时的 KL 散度形式为： \(KL(q(x_0|x_1,x_0)||p_\theta(x_0|x_1))\) 但是 \(q(x_0|x_1,x_0)\) 是一个退化分布，退化分布与一半分布的 KL 散度不能写成常规形式，否则会遇到奇异性问题。</p> </blockquote> <h3 id="加噪技巧">加噪技巧</h3> <p>由于 DDPM 的性质，加噪是一步一步地进行的。这是否意味着我们如果想得到一张时间步 \(t\) 的加噪图像，我们真的需要老老实实地加噪 \(t\) 次呢？NO！实际上我们有：</p> \[q(x_t|x_0)=\mathcal{N}(x_t;\sqrt{\bar{\alpha_t}}x_0,(1-\bar{\alpha_t})\mathbf{I}) \\ \alpha:=1-\beta_t \\ \bar{\alpha_t}:=\prod_{s=1}^t\alpha_s\] <blockquote> <p>[!note]</p> <p>根据加噪的定义 \(q(x_t|x_{t-1})=\mathcal{N}(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_t \mathbf{I})\) ，我们可以将它重新写为递推形式： \(x_t=\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}\epsilon_t \\ \epsilon \sim \mathcal{N}(0,\mathbf{I})\) 我们递归地展开一项这个递推式，可以得到： \(x_{t+1}=\sqrt{\alpha_{t+1}}(\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}\epsilon_t)+\sqrt{1-\alpha_{t+1}}\epsilon_{t+1} \\ =\sqrt{\alpha_{t+1}\alpha_t}x_{t-1}+\sqrt{\alpha_{t+1}(1-\alpha_t)}\epsilon_t+\sqrt{1-\alpha_{t+1}}\epsilon_{t+1}\) 如果一直展开到 \(x_0\) ，我们有： \(x_t=\sqrt{\prod_{s=1}^t\alpha_s}x_0+\sum_{s=1}^t\sqrt{(1-\alpha_s)\prod_{j=s+1}^t\alpha_j}\epsilon_s\) 方差项通过数学归纳法可以发现等同于 \(1-\bar{\alpha}_t\)，均值项显然。</p> </blockquote> <h3 id="去噪技巧">去噪技巧</h3> <p>由于加噪的分布和尝试学习的分布都是高斯分布，根据多元高斯 KL 公式，\(L_{t-1}\) 可以被重写为<a href="#证明附录">如下形式：</a></p> \[L_{t-1}=\mathbb{E}_q[\frac{1}{2\sigma_t^2}||\tilde{\mu}_t(x_t,x_0)-\mu_\theta(x_t,t)||^2]+C\] <blockquote> <p>[!note]</p> <p>可以算出： \(q(x_{t-1}|x_t,x_0)=\mathcal{N}(x_{t-1};\tilde{\mu}_t(x_t,x_0),\tilde{\beta}_t\mathbf{I}) \\ \tilde \mu_t(x_t,x_0):=\frac{\sqrt{\bar \alpha_{t-1}}\beta_t}{1-\bar \alpha_t}x_0+\frac{\sqrt {\alpha_t}(1-\bar \alpha_{t-1})}{1-\bar \alpha_t}x_t \\ \tilde \beta_t:=\frac{1-\bar{\alpha}_{t-1}}{1-\bar \alpha_t}\beta_t\)</p> </blockquote> <blockquote> <p>[!important]</p> <p>这里可能存在一个疑惑：对 \(q\) 求期望，但是期望项里并没有出现 \(q\) 啊？在这里我们可以把 \(q\) 理解为一次采样过程。其中 \(x_t\) 和 \(t\) 就是在时间步 \(t\) 时的结果。</p> </blockquote> <p>对于重写的损失形式，一个直觉是我们直接学习 \(\tilde \mu_t\) 。然而通过进一步展开上述损失，我们可以得到：</p> \[L_{t-1}-C=\mathbb E_{x_0,\epsilon}[\frac{1}{2\sigma^2_t}||\frac{1}{\sqrt \alpha_t}(x_t(x_0,\epsilon)-\frac{\beta_t}{\sqrt{1-\bar \alpha_t}}\epsilon)-\mu_\theta(x_t(x_0,\epsilon),t)||^2]\] <p>因此在去噪的时候，DDPM 实际上是先学习去噪分布的均值 \(\mu_\theta(x_t,t)=\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar \alpha_t}}\epsilon)\)，再在这个均值上添加一个随机噪声 \(x_{t-1}=\mu_\theta(x_t,t)+\sigma_t\mathbf z\)，得到去噪图像的。</p> <p>一种现在更常见的操作是预测噪声：注意到上面对均值的预测中，由于 \(x_t\) 可以直接作为输入，实际上只有噪声是需要预测的未知量。因此一个motivating 的选择是：</p> \[\mu_\theta(x_t,t)=\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\bar \alpha_t}}\epsilon_\theta(x_t,t))\] <p>将其重新带回重写后的损失函数后可以得到：</p> \[L_{t-1}-C=\mathbb{E}_{x_0,\epsilon}[\frac{\beta_t^2}{2\sigma^2_t(1-\bar \alpha_t)}||\epsilon-\epsilon_\theta(\sqrt{\bar \alpha_t}x_0+\sqrt{1-\bar \alpha_t }\epsilon,t)||^2]\] <p>这样做的好处是，网络只需要学习一个更为简洁的函数。</p> <blockquote> <p>[!note]</p> <p>\(\epsilon_\theta\) 是噪声预测器，用来预测噪声，\(\mu_\theta\) 用来预测去噪结果的均值。在这次重写中我们把一次采样过程分解为了两步：采样原始图像与采样噪声。</p> <p>这里有值得注意的一点：\(\mathbf{z}\) 代表的并不是所谓的噪音，而是一种随机采样。这很像 VAE 中的重参数化技巧：去噪结果实际上也是一个随机变量，是神经网络无法学习的。但是我们可以通过学习这个分布的均值，并随机给这个均值加上一个高斯分布的采样结果，来实现随机化。</p> </blockquote> <h2 id="工程实现">工程实现</h2> <h3 id="数据预处理">数据预处理</h3> <h4 id="数据放缩">数据放缩</h4> <p>DDPM 在原始论文中指出，他们驶使用的图片数据集由 0-255 的整数构成。他们将数据范围从 0-255 线性地缩小到了 [-1,1]</p> <h4 id="解码器">解码器</h4> <p>在反向过程中，由于去噪过程中会出现对高斯分布采样结果的加减，这导致我们最后得到数据不一定能通过数据放缩的逆过程重新转化为 0-255 的整数。因此 ddpm 选择在 \(x_1\) 进行去噪的过程中，直接计算每一个像素点是 0-255 的概率。解码公式如下：</p> \[p_\theta(x_0|x_1)=\prod_{i=1}^D\int_{\delta_\_(x_0^i)}^{\delta_+(x_0^i)}\mathcal{N}(x;\mu_\theta^i(x_1,1),\sigma^2_1)dx \\ \delta^+(x) = \begin{cases} +\infty, &amp; x = 1 \\ x + \tfrac{1}{255}, &amp; x &lt; 1 \end{cases} \quad \quad \delta^-(x) = \begin{cases} -\infty, &amp; x = -1 \\ x - \tfrac{1}{255}, &amp; x &gt; -1 \end{cases}\] <p>公式看上去吓人，但是实际上是一个很直观的结果：在预测完 \(x_0\) 的均值后，我们得到一个关于这个均值的高斯分布。通过将这个分布在 x 轴等分 256 份，并计算每部分的面积，我们实际上就得到了高斯分布采样落在这每一部分的概率。第 k 份的区间是 \([k-\frac{1}{255},k+\frac{1}{255}]\)，代表着落在整数 k 附近的概率。这样我们就得到了每个像素点取值的概率分布，我们可以根据不同的选取策略进行实际的赋值。</p> <h3 id="训练过程">训练过程</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">each</span> <span class="n">training</span> <span class="n">step</span><span class="p">:</span>
    <span class="n">x0</span> <span class="o">~</span> <span class="n">dataset</span>                          <span class="c1"># 从数据集中采样图像
</span>    <span class="n">t</span> <span class="o">~</span> <span class="nc">Uniform</span><span class="p">({</span><span class="mi">1</span><span class="p">,...,</span><span class="n">T</span><span class="p">})</span>                <span class="c1"># 随机选择一个时间步 t
</span>    <span class="n">ε</span> <span class="o">~</span> <span class="nc">N</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">I</span><span class="p">)</span>                            <span class="c1"># 采样标准高斯噪声
</span>    <span class="n">xt</span> <span class="o">=</span> <span class="nf">sqrt</span><span class="p">(</span><span class="n">alpha_bar_t</span><span class="p">)</span><span class="o">*</span><span class="n">x0</span> <span class="o">+</span> <span class="nf">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha_bar_t</span><span class="p">)</span><span class="o">*</span><span class="n">ε</span>  <span class="c1"># 添加噪声，alpha_bar_t = ∏_{s=1}^t (1-βs)
</span>    
    <span class="c1"># 预测噪声并计算损失
</span>    <span class="n">ε_theta</span> <span class="o">=</span> <span class="nf">neural_net</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">||</span><span class="n">ε</span> <span class="o">-</span> <span class="n">ε_theta</span><span class="o">||^</span><span class="mi">2</span>               <span class="c1"># L2损失
</span>    
    <span class="n">θ</span> <span class="o">=</span> <span class="n">θ</span> <span class="o">-</span> <span class="n">lr</span> <span class="o">*</span> <span class="err">∇</span><span class="n">_θ</span> <span class="n">loss</span>                  <span class="c1"># 更新网络参数
</span></code></pre></div></div> <h3 id="生成过程">生成过程</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 初始化
</span><span class="n">x_T</span> <span class="o">~</span> <span class="nc">N</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">I</span><span class="p">)</span>                             <span class="c1"># 从纯高斯噪声开始
</span>
<span class="c1"># 逐步去噪
</span><span class="k">for</span> <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">,...,</span><span class="mi">2</span><span class="p">:</span>                          <span class="c1"># 注意最后一步单独处理
</span>    <span class="n">ε_theta</span> <span class="o">=</span> <span class="nf">neural_net</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>          <span class="c1"># 预测噪声
</span>    <span class="n">μ_t</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">β_t</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x_t</span> <span class="o">-</span> <span class="n">β_t</span><span class="o">/</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">alpha_bar_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">ε_theta</span><span class="p">)</span>  <span class="c1"># 均值更新公式
</span>    <span class="n">z</span> <span class="o">~</span> <span class="nc">N</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">I</span><span class="p">)</span>                            <span class="c1"># 随机高斯噪声
</span>    <span class="n">x_</span><span class="p">{</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">}</span> <span class="o">=</span> <span class="n">μ_t</span> <span class="o">+</span> <span class="nf">sqrt</span><span class="p">(</span><span class="n">β_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">z</span>         <span class="c1"># 采样下一步
</span>
<span class="c1"># 最后一步 t = 1，使用离散解码器生成整数像素
</span><span class="n">μ_1</span> <span class="o">=</span> <span class="nf">neural_net</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">σ_1</span> <span class="o">=</span> <span class="nf">sqrt</span><span class="p">(</span><span class="n">β_1</span><span class="p">)</span>
<span class="n">x_0</span> <span class="o">=</span> <span class="nf">discretized_decoder</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">μ_1</span><span class="p">,</span> <span class="n">σ_1</span><span class="p">)</span>  <span class="c1"># 高斯积分得到 0-255 的像素值
</span>
<span class="k">return</span> <span class="n">x_0</span>                                <span class="c1"># 最终生成图像
</span></code></pre></div></div> <h2 id="接下来要干啥">接下来要干啥</h2> <p>注意到，在对 DDPM 的原理进行介绍的时候，并没有提到 prompt 的问题。这是因为 DDPM 是一个无条件模型，因此不能人为地控制 DDPM 图像的输出。因此产生了 CDDPM。另外，扩散模型的非平衡态热力学的原理看上去也十分有趣。在<del>不</del>遥远的未来，我将尝试对这两个方面进行探究。</p> <h2 id="证明附录">证明附录</h2> <h3 id="变分下界证明">变分下界证明</h3> \[\log p_\theta(x_0)=\log \int p_\theta(x_{0:T})dx_{1:T}=\log \int q(x_{1:T}|x_0)\frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)}dx_{1:T}\] <p>利用 Jensen 不等式：</p> \[f(\mathbb{E}[X]) \le \mathbb{E}[f(X)], \text{where} f\text{ is convex}\] <table> <tbody> <tr> <td>令 $$X=\frac{p_\theta(x_{0:T})}{q(x_{1:T}</td> <td>x_0)}\sim q, f=\log$$，可以得到：</td> </tr> </tbody> </table> \[\log p_\theta(x_0) \ge \mathbb{E}[\log p_\theta(x_{0:T})-\log q(x_{1:T}|x_0)]\] <p>将 \(p_\theta\) 和 \(q\) 展开得到：</p> \[p_\theta(x_{0:T})=p(x_T)\prod_{t=1}^Tp_\theta(x_{t-1}|x_t) \\ q(x_{1:T}|x_0)=\prod_{t=1}^Tq(x_t|x_{t-1})\] <p>将这两项带入上面不等式的右侧，可以得到：</p> \[\log p_\theta(x_{0:T})-\log q(x_{1:T}|x_0) = - \log p(x_T)-\sum_{t=1}^T \log\frac{p_\theta(x_{t-1}|x_t)}{q(x_t|x_{t-1})}\] <p>将结果带入回不等式的右侧，得到我们想要的结果。注意最后不等式的右边是两层期望：先对辅助分布 \(q\) 求期望，再对 \(x_0\) 求期望。</p> <h3 id="其它的">其它的</h3> <p>鸽了鸽了，写不动了(</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="math"/><summary type="html"><![CDATA[test qwq]]></summary></entry><entry><title type="html">a post with plotly.js</title><link href="https://chusi-truth.github.io/blog/2025/plotly/" rel="alternate" type="text/html" title="a post with plotly.js"/><published>2025-03-26T14:24:00+00:00</published><updated>2025-03-26T14:24:00+00:00</updated><id>https://chusi-truth.github.io/blog/2025/plotly</id><content type="html" xml:base="https://chusi-truth.github.io/blog/2025/plotly/"><![CDATA[<p>This is an example post with some <a href="https://plotly.com/javascript/">plotly</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">plotly
</span><span class="sb">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "type": "scatter"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [16, 5, 11, 9],
      "type": "scatter"
    }
  ]
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-plotly">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "type": "scatter"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [16, 5, 11, 9],
      "type": "scatter"
    }
  ]
}
</code></pre> <p>Also another example chart.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">plotly
</span><span class="sb">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "mode": "markers"
    },
    {
      "x": [2, 3, 4, 5],
      "y": [16, 5, 11, 9],
      "mode": "lines"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [12, 9, 15, 12],
      "mode": "lines+markers"
    }
  ],
  "layout": {
    "title": {
      "text": "Line and Scatter Plot"
    }
  }
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>This is how it looks like:</p> <pre><code class="language-plotly">{
  "data": [
    {
      "x": [1, 2, 3, 4],
      "y": [10, 15, 13, 17],
      "mode": "markers"
    },
    {
      "x": [2, 3, 4, 5],
      "y": [16, 5, 11, 9],
      "mode": "lines"
    },
    {
      "x": [1, 2, 3, 4],
      "y": [12, 9, 15, 12],
      "mode": "lines+markers"
    }
  ],
  "layout": {
    "title": {
      "text": "Line and Scatter Plot"
    }
  }
}
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="charts"/><summary type="html"><![CDATA[this is what included plotly.js code could look like]]></summary></entry><entry><title type="html">a post with image galleries</title><link href="https://chusi-truth.github.io/blog/2024/photo-gallery/" rel="alternate" type="text/html" title="a post with image galleries"/><published>2024-12-04T01:59:00+00:00</published><updated>2024-12-04T01:59:00+00:00</updated><id>https://chusi-truth.github.io/blog/2024/photo-gallery</id><content type="html" xml:base="https://chusi-truth.github.io/blog/2024/photo-gallery/"><![CDATA[<p>The images in this post are all zoomable, arranged into different mini-galleries using different libraries.</p> <h2 id="lightbox2"><a href="https://lokeshdhakar.com/projects/lightbox2/">Lightbox2</a></h2> <p><a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/></a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/></a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg" data-lightbox="roadtrip"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/></a></p> <hr/> <h2 id="photoswipe"><a href="https://photoswipe.com/">PhotoSwipe</a></h2> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--getting-started"> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg" data-pswp-width="1669" data-pswp-height="2500" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg" alt=""/> </a> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/7/img-2500.jpg" data-pswp-width="1875" data-pswp-height="2500" data-cropped="true" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/7/img-200.jpg" alt=""/> </a> <a href="https://unsplash.com" data-pswp-src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg" data-pswp-width="2500" data-pswp-height="1666" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg" alt=""/> </a> <div> <a href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-2500.jpg" data-pswp-width="2500" data-pswp-height="1667" target="_blank"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-200.jpg" alt=""/> </a> </div> </div> <hr/> <h2 id="spotlight-js"><a href="https://nextapps-de.github.io/spotlight/">Spotlight JS</a></h2> <div class="spotlight-group"> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/> </a> </div> <div class="spotlight-group"> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/4/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/4/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/5/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/5/img-200.jpg"/> </a> <a class="spotlight" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-2500.jpg"> <img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/6/img-200.jpg"/> </a> </div> <hr/> <h2 id="venobox"><a href="https://veno.es/venobox/">Venobox</a></h2> <p><a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/1/img-200.jpg"/></a> <a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/2/img-200.jpg"/></a> <a class="venobox" data-gall="myGallery" href="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-2500.jpg"><img src="https://cdn.photoswipe.com/photoswipe-demo-images/photos/3/img-200.jpg"/></a></p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="images"/><summary type="html"><![CDATA[this is what included image galleries could look like]]></summary></entry><entry><title type="html">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</title><link href="https://chusi-truth.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/" rel="alternate" type="text/html" title="Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://chusi-truth.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra</id><content type="html" xml:base="https://chusi-truth.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/"><![CDATA[<p>May 14, 2024 We’re introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants. In December, we launched our first natively multimodal model Gemini 1.0 in three sizes: Ultra, Pro and Nano. Just a few months later we released 1.5 Pro, with enhanced performance and a breakthrough long context window of 1 million tokens.Developers and enterprise customers have been putting 1.5 Pro to use in incredible ways and finding its long context window, multimodal reasoning capabilities and impressive overall performance incredibly useful.We know from user feedback that some applications need lower latency and a lower cost to serve. This inspired us to keep innovating, so today, we’re introducing Gemini 1.5 Flash: a model that’s lighter-weight than 1.5 Pro, and designed to be fast and efficient to serve at scale.Both 1.5 Pro and 1.5 Flash are available in public preview with a 1 million token context window in Google AI Studio and Vertex AI. And now, 1.5 Pro is also available with a 2 million token context window via waitlist to developers using the API and to Google Cloud customers.We’re also introducing updates across the Gemini family of models, announcing our next generation of open models, Gemma 2, and sharing progress on the future of AI assistants, with Project Astra.Context lengths of leading foundation models compared with Gemini 1.5’s 2 million token capability1.5 Flash is the newest addition to the Gemini model family and the fastest Gemini model served in the API. It’s optimized for high-volume, high-frequency tasks at scale, is more cost-efficient to serve and features our breakthrough long context window.While it’s a lighter weight model than 1.5 Pro, it’s highly capable of multimodal reasoning across vast amounts of information and delivers impressive quality for its size.The new Gemini 1.5 Flash model is optimized for speed and efficiency, is highly capable of multimodal reasoning and features our breakthrough long context window.1.5 Flash excels at summarization, chat applications, image and video captioning, data extraction from long documents and tables, and more. This is because it’s been trained by 1.5 Pro through a process called “distillation,” where the most essential knowledge and skills from a larger model are transferred to a smaller, more efficient model.Read more about 1.5 Flash in our updated Gemini 1.5 technical report, on the Gemini technology page, and learn about 1.5 Flash’s availability and pricing.Over the last few months, we’ve significantly improved 1.5 Pro, our best model for general performance across a wide range of tasks.Beyond extending its context window to 2 million tokens, we’ve enhanced its code generation, logical reasoning and planning, multi-turn conversation, and audio and image understanding through data and algorithmic advances. We see strong improvements on public and internal benchmarks for each of these tasks.1.5 Pro can now follow increasingly complex and nuanced instructions, including ones that specify product-level behavior involving role, format and style. We’ve improved control over the model’s responses for specific use cases, like crafting the persona and response style of a chat agent or automating workflows through multiple function calls. And we’ve enabled users to steer model behavior by setting system instructions.We added audio understanding in the Gemini API and Google AI Studio, so 1.5 Pro can now reason across image and audio for videos uploaded in Google AI Studio. And we’re now integrating 1.5 Pro into Google products, including Gemini Advanced and in Workspace apps.Read more about 1.5 Pro in our updated Gemini 1.5 technical report and on the Gemini technology page.Gemini Nano is expanding beyond text-only inputs to include images as well. Starting with Pixel, applications using Gemini Nano with Multimodality will be able to understand the world the way people do — not just through text, but also through sight, sound and spoken language.Read more about Gemini 1.0 Nano on Android.Today, we’re also sharing a series of updates to Gemma, our family of open models built from the same research and technology used to create the Gemini models.We’re announcing Gemma 2, our next generation of open models for responsible AI innovation. Gemma 2 has a new architecture designed for breakthrough performance and efficiency, and will be available in new sizes.The Gemma family is also expanding with PaliGemma, our first vision-language model inspired by PaLI-3. And we’ve upgraded our Responsible Generative AI Toolkit with LLM Comparator for evaluating the quality of model responses.Read more on the Developer blog.As part of Google DeepMind’s mission to build AI responsibly to benefit humanity, we’ve always wanted to develop universal AI agents that can be helpful in everyday life. That’s why today, we’re sharing our progress in building the future of AI assistants with Project Astra (advanced seeing and talking responsive agent).To be truly useful, an agent needs to understand and respond to the complex and dynamic world just like people do — and take in and remember what it sees and hears to understand context and take action. It also needs to be proactive, teachable and personal, so users can talk to it naturally and without lag or delay.While we’ve made incredible progress developing AI systems that can understand multimodal information, getting response time down to something conversational is a difficult engineering challenge. Over the past few years, we’ve been working to improve how our models perceive, reason and converse to make the pace and quality of interaction feel more natural.Building on Gemini, we’ve developed prototype agents that can process information faster by continuously encoding video frames, combining the video and speech input into a timeline of events, and caching this information for efficient recall.By leveraging our leading speech models, we also enhanced how they sound, giving the agents a wider range of intonations. These agents can better understand the context they’re being used in, and respond quickly, in conversation.With technology like this, it’s easy to envision a future where people could have an expert AI assistant by their side, through a phone or glasses. And some of these capabilities are coming to Google products, like the Gemini app and web experience, later this year.We’ve made incredible progress so far with our family of Gemini models, and we’re always striving to advance the state-of-the-art even further. By investing in a relentless production line of innovation, we’re able to explore new ideas at the frontier, while also unlocking the possibility of new and exciting Gemini use cases.Learn more about Gemini and its capabilities. Your information will be used in accordance with Google’s privacy policy.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      Done. Just one step more.
    
      Check your inbox to confirm your subscription.
    You are already subscribed to our newsletter.
    You can also subscribe with a
    different email address
    
    .
    
  Let’s stay in touch. Get the latest news from Google in your inbox.
          Follow Us
</code></pre></div></div>]]></content><author><name></name></author><summary type="html"><![CDATA[We’re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.]]></summary></entry><entry><title type="html">a post with tabs</title><link href="https://chusi-truth.github.io/blog/2024/tabs/" rel="alternate" type="text/html" title="a post with tabs"/><published>2024-05-01T00:32:13+00:00</published><updated>2024-05-01T00:32:13+00:00</updated><id>https://chusi-truth.github.io/blog/2024/tabs</id><content type="html" xml:base="https://chusi-truth.github.io/blog/2024/tabs/"><![CDATA[<p>This is how a post with <a href="https://github.com/Ovski4/jekyll-tabs">tabs</a> looks like. Note that the tabs could be used for different purposes, not only for code.</p> <h2 id="first-tabs">First tabs</h2> <p>To add tabs, use the following syntax:</p> <div class="language-liquid highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">{%</span><span class="w"> </span><span class="nt">tabs</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-1</span><span class="w"> </span><span class="cp">%}</span>

Content 1

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-2</span><span class="w"> </span><span class="cp">%}</span>

Content 2

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtabs</span><span class="w"> </span><span class="cp">%}</span>
</code></pre></div></div> <p>With this you can generate visualizations like:</p> <ul id="log" class="tab" data-tab="6a9cc582-ab46-44d7-8660-3573422c47cb" data-name="log"> <li class="active" id="log-php"> <a href="#">php </a> </li> <li id="log-js"> <a href="#">js </a> </li> <li id="log-ruby"> <a href="#">ruby </a> </li> </ul> <ul class="tab-content" id="6a9cc582-ab46-44d7-8660-3573422c47cb" data-name="log"> <li class="active"> <div class="language-php highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">var_dump</span><span class="p">(</span><span class="s1">'hello'</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="dl">"</span><span class="s2">hello</span><span class="dl">"</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">pputs</span> <span class="dl">'</span><span class="s1">hello</span><span class="dl">'</span>
</code></pre></div></div> </li> </ul> <h2 id="another-example">Another example</h2> <ul id="data-struct" class="tab" data-tab="99182312-ab0b-4bd3-87de-b10f43425f47" data-name="data-struct"> <li class="active" id="data-struct-yaml"> <a href="#">yaml </a> </li> <li id="data-struct-json"> <a href="#">json </a> </li> </ul> <ul class="tab-content" id="99182312-ab0b-4bd3-87de-b10f43425f47" data-name="data-struct"> <li class="active"> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">hello</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">whatsup"</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">hi"</span>
</code></pre></div></div> </li> <li> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"hello"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"whatsup"</span><span class="p">,</span><span class="w"> </span><span class="s2">"hi"</span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> </li> </ul> <h2 id="tabs-for-something-else">Tabs for something else</h2> <ul id="something-else" class="tab" data-tab="faa39939-d34a-4d4e-bb53-26b4c80735f4" data-name="something-else"> <li class="active" id="something-else-text"> <a href="#">text </a> </li> <li id="something-else-quote"> <a href="#">quote </a> </li> <li id="something-else-list"> <a href="#">list </a> </li> </ul> <ul class="tab-content" id="faa39939-d34a-4d4e-bb53-26b4c80735f4" data-name="something-else"> <li class="active"> <p>Regular text</p> </li> <li> <blockquote> <p>A quote</p> </blockquote> </li> <li> <p>Hipster list</p> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is what included tabs in a post could look like]]></summary></entry><entry><title type="html">a post with typograms</title><link href="https://chusi-truth.github.io/blog/2024/typograms/" rel="alternate" type="text/html" title="a post with typograms"/><published>2024-04-29T23:36:10+00:00</published><updated>2024-04-29T23:36:10+00:00</updated><id>https://chusi-truth.github.io/blog/2024/typograms</id><content type="html" xml:base="https://chusi-truth.github.io/blog/2024/typograms/"><![CDATA[<p>This is an example post with some <a href="https://github.com/google/typograms/">typograms</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">+----+
|    |---&gt; My first diagram!
+----+</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-typograms">+----+
|    |---&gt; My first diagram!
+----+
</code></pre> <p>Another example:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.</span>
<span class="p">```</span>
</code></pre></div></div> <p>which generates:</p> <pre><code class="language-typograms">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.
</code></pre> <p>For more examples, check out the <a href="https://google.github.io/typograms/#examples">typograms documentation</a>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="diagrams"/><summary type="html"><![CDATA[this is what included typograms code could look like]]></summary></entry><entry><title type="html">a post that can be cited</title><link href="https://chusi-truth.github.io/blog/2024/post-citation/" rel="alternate" type="text/html" title="a post that can be cited"/><published>2024-04-28T15:06:00+00:00</published><updated>2024-04-28T15:06:00+00:00</updated><id>https://chusi-truth.github.io/blog/2024/post-citation</id><content type="html" xml:base="https://chusi-truth.github.io/blog/2024/post-citation/"><![CDATA[<p>This is an example post that can be cited. The content of the post ends here, while the citation information is automatically provided below. The only thing needed is for you to set the <code class="language-plaintext highlighter-rouge">citation</code> key in the front matter to <code class="language-plaintext highlighter-rouge">true</code>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="citation"/><summary type="html"><![CDATA[this is what a post that can be cited looks like]]></summary></entry></feed>